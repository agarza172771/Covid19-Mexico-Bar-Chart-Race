{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 2: Data Cleaning\n",
    "\n",
    "In this module, the file containing the data and the catalog are read. Here the files will \n",
    "be simplified and 2 cvs files will be generated, one of accumulated data and the other \n",
    "of daily data. Note that the data we are going to take are very clean, in the sense that \n",
    "they are captured correctly. The data is prepared to generate the bar race graph. In addition \n",
    "to this, only active cases data are considered.\n",
    "\n",
    "\n",
    "En este modulo, se leen el archivo donde estan los datos y el catalogo. Aqui se simmplificaran los \n",
    "archivos y se generan 2 archivos cvs, uno de datos acumulados y el otro de datos diarios. Notemos que\n",
    "los datos que vamos a tomar estan muy limpios, en el sentido de que estan capturados correctamente. Los\n",
    "datos se preparan para generar la grafica de carrera de barras. Adiconal a esto, se toman los datos\n",
    "de casos activos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '.'\n",
    "files_in_dir = []\n",
    "var = 'FECHA_SINTOMAS'\n",
    "\n",
    "# r=>root, d=>directories, f=>files\n",
    "for r, d, f in os.walk(location):\n",
    "    for item in f:\n",
    "        if ('.csv' in item):     \n",
    "            files_in_dir.append(os.path.join(r, item))\n",
    "        if ('.xlsx' in item):\n",
    "            files_in_dir.append(os.path.join(r, item))\n",
    "            \n",
    "df = pd.read_csv(files_in_dir[0],engine='python',index_col=var, parse_dates=[var])\n",
    "en = pd.read_excel(files_in_dir[1],sheet_name='Cat√°logo de ENTIDADES')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Note1: Before run twice this Mod, you need to run Mod01 first, or run line by line.\n",
    "Note2: To consider only active cases, it si needed to drop all the columns, excep 'FECHA_SINTOMAS'\n",
    "\n",
    "Only the cases when the symptoms started were considered, no other case is taken into account. \n",
    "So the remaining columns are discarded.\n",
    "\n",
    "To coincide with the official numbers, it is necessary to take into account only 'RESULT' = 1, \n",
    "which are the confirmed cases.\n",
    "\n",
    "Solo se consideraran los casos cuando empezaron los sintomas, ningun otro caso se toma en cuenta. Asi que \n",
    "las columnas restantes se desechan.\n",
    "\n",
    "Para coincidir con los numeros oficiales hay qe tomar en cuenta solo 'RESULTADO' = 1 \n",
    "que son los casos confirmados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['FECHA_ACTUALIZACION', 'ID_REGISTRO', 'ORIGEN', 'SECTOR', 'ENTIDAD_UM',\n",
    "       'SEXO', 'ENTIDAD_NAC', 'MUNICIPIO_RES', 'TIPO_PACIENTE', 'FECHA_DEF',\n",
    "       'FECHA_INGRESO', 'INTUBADO', 'NEUMONIA', 'EDAD',\n",
    "       'NACIONALIDAD', 'EMBARAZO', 'HABLA_LENGUA_INDIG', 'DIABETES', 'EPOC',\n",
    "       'ASMA', 'INMUSUPR', 'HIPERTENSION', 'OTRA_COM', 'CARDIOVASCULAR',\n",
    "       'OBESIDAD', 'RENAL_CRONICA', 'TABAQUISMO', 'OTRO_CASO',\n",
    "       'MIGRANTE', 'PAIS_NACIONALIDAD', 'PAIS_ORIGEN', 'UCI'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENTIDAD_RES'].replace(to_replace=en['CLAVE_ENTIDAD'].tolist(), \n",
    "                          value=en['ENTIDAD_FEDERATIVA'].tolist(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[(df['RESULTADO']!=2) & (df['RESULTADO']!=3)].drop('RESULTADO', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.pivot_table(df0, values='ENTIDAD_RES',  index=var, \n",
    "                     columns='ENTIDAD_RES',aggfunc=len, fill_value=0).cumsum().reset_index()\n",
    "\n",
    "df2 = pd.pivot_table(df0, values='ENTIDAD_RES',  index=var, \n",
    "                     columns='ENTIDAD_RES',aggfunc=len, fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./data/porentidad.csv', encoding='utf-8',index=False)    #Cummulative: used to bar chart race\n",
    "\n",
    "df2.to_csv('./data/porentidad2.csv', encoding='utf-8',index=False)   #Non cummulative: to be used for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module #02 finished\n"
     ]
    }
   ],
   "source": [
    "print('Module #02 finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
